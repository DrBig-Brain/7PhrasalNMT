{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fdad08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import spacy\n",
    "from utils import build_phrase_vocab\n",
    "from pre_processing import preprocess_with_phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474de27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_len = 128\n",
    "min_len = 5\n",
    "\n",
    "en_texts, hi_texts = ..., ...\n",
    "en_proc, hi_proc, phrase_tags = preprocess_with_phrases(en_texts, hi_texts, min_len, sequence_len)\n",
    "phrase2idx = build_phrase_vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1332ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharPhraseDataset(Dataset):\n",
    "    def __init__(self, x, y, phrases, sequence_len, ch2i, phrase2idx):\n",
    "        self.x, self.y, self.phrases = x, y, phrases\n",
    "        self.sequence_len = sequence_len\n",
    "        self.ch2i = ch2i\n",
    "        self.phrase2idx = phrase2idx\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = [self.ch2i.get(c, 0) for c in self.x[idx]]\n",
    "        y = [self.ch2i.get(c, 0) for c in self.y[idx]]\n",
    "        p = [self.phrase2idx.get(tag, 0) for tag in self.phrases[idx]]\n",
    "        # Padding if needed\n",
    "        x = x[:self.sequence_len] + [0]*(self.sequence_len - len(x))\n",
    "        y = y[:self.sequence_len] + [0]*(self.sequence_len - len(y))\n",
    "        p = p[:self.sequence_len] + [0]*(self.sequence_len - len(p))\n",
    "        return torch.tensor(x), torch.tensor(y), torch.tensor(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832bcf42",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = set(''.join(en_proc + hi_proc))\n",
    "ch2i = {c: i for i, c in enumerate(['<pad>'] + sorted(list(chars)))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c84a3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CharPhraseDataset(en_proc, hi_proc, phrase_tags, sequence_len, ch2i, phrase2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9621be52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer import TransformerWithPhrase\n",
    "\n",
    "mconfig = ...  # transformer config as per your code\n",
    "model = TransformerWithPhrase(mconfig, phrase_vocab_size=len(phrase2idx), phrase_emb_dim=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c6815a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trainer import Trainer, TrainerConfig\n",
    "trainer_config = TrainerConfig(...)\n",
    "trainer = Trainer(model, dataset, trainer_config)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f8d793",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sents = [...]\n",
    "test_phrases = [extract_7_phrases(s) for s in test_sents]\n",
    "test_p = [[phrase2idx.get(tag, 0) for tag in tags] + [0]*(sequence_len-len(tags)) for tags in test_phrases]\n",
    "test_x = [[ch2i.get(c, 0) for c in s] + [0]*(sequence_len-len(s)) for s in test_sents]\n",
    "test_x = torch.tensor(test_x)\n",
    "test_p = torch.tensor(test_p)\n",
    "with torch.no_grad():\n",
    "    translations = model.generate(test_x, test_p)\n",
    "print(translations)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

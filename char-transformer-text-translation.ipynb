{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fdad08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import spacy\n",
    "from utils import build_phrase_vocab\n",
    "from preprocessing import preprocess_with_phrases  # fixed typo: pre_processing -> preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474de27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_len = 128\n",
    "min_len = 5\n",
    "\n",
    "# Replace with your English-Hindi parallel data\n",
    "en_texts = [\"Hello world.\", \"How are you?\"]\n",
    "hi_texts = [\"नमस्ते दुनिया।\", \"आप कैसे हैं?\"]\n",
    "# Preprocessing: phrase extraction is performed on English sentences\n",
    "en_proc, hi_proc, phrase_tags = preprocess_with_phrases(en_texts, hi_texts, min_len, sequence_len)\n",
    "phrase2idx = build_phrase_vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1332ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharPhraseDataset(Dataset):\n",
    "    def __init__(self, x, y, phrases, sequence_len, ch2i, phrase2idx):\n",
    "        self.x, self.y, self.phrases = x, y, phrases\n",
    "        self.sequence_len = sequence_len\n",
    "        self.ch2i = ch2i\n",
    "        self.phrase2idx = phrase2idx\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = [self.ch2i.get(c, 0) for c in self.x[idx]]\n",
    "        y = [self.ch2i.get(c, 0) for c in self.y[idx]]\n",
    "        p = [self.phrase2idx.get(tag, 0) for tag in self.phrases[idx]]\n",
    "        # Padding if needed\n",
    "        x = x[:self.sequence_len] + [0]*(self.sequence_len - len(x))\n",
    "        y = y[:self.sequence_len] + [0]*(self.sequence_len - len(y))\n",
    "        p = p[:self.sequence_len] + [0]*(self.sequence_len - len(p))\n",
    "        return torch.tensor(x), torch.tensor(y), torch.tensor(p)\n",
    "# This dataset is now set up for English-Hindi translation (x: English, y: Hindi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832bcf42",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = set(''.join(en_proc + hi_proc))\n",
    "ch2i = {c: i for i, c in enumerate(['<pad>'] + sorted(list(chars)))}\n",
    "# ch2i covers both English and Hindi characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c84a3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CharPhraseDataset(en_proc, hi_proc, phrase_tags, sequence_len, ch2i, phrase2idx)\n",
    "# en_proc: English, hi_proc: Hindi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9621be52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer import TransformerWithPhrase\n",
    "\n",
    "from transformer import TransformerConfig\n",
    "mconfig = TransformerConfig(\n",
    "    vocab_size=len(ch2i),\n",
    "    sequence_len=sequence_len,\n",
    "    nblock=4,\n",
    "    nhead=8,\n",
    "    embed_dim=256,\n",
    "    phrase_emb_dim=16\n",
    ")\n",
    "model = TransformerWithPhrase(mconfig, phrase_vocab_size=len(phrase2idx), phrase_emb_dim=16)\n",
    "# Model is set up for English-to-Hindi translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c6815a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trainer import Trainer, TrainerConfig\n",
    "trainer_config = TrainerConfig(max_epochs=10, batch_size=64, learning_rate=3e-4, device='cuda' if torch.cuda.is_available() else 'cpu')\n",
    "trainer = Trainer(model, dataset, trainer_config)\n",
    "trainer.train()\n",
    "# Training for English-to-Hindi translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f8d793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: test English sentences for translation to Hindi\n",
    "test_sents = [\"This is a test.\", \"Translate this sentence.\"]\n",
    "test_phrases = [extract_7_phrases(s) for s in test_sents]  # phrase extraction on English\n",
    "test_p = [[phrase2idx.get(tag, 0) for tag in tags] + [0]*(sequence_len-len(tags)) for tags in test_phrases]\n",
    "test_x = [[ch2i.get(c, 0) for c in s] + [0]*(sequence_len-len(s)) for s in test_sents]\n",
    "device = trainer_config.device\n",
    "test_x = torch.tensor(test_x).to(device)\n",
    "test_p = torch.tensor(test_p).to(device)\n",
    "with torch.no_grad():\n",
    "    translations = model.generate(test_x, test_p)\n",
    "\n",
    "# Decoding: convert output indices to text\n",
    "# Build inverse mapping\n",
    "i2ch = {i: c for c, i in ch2i.items()}\n",
    "\n",
    "def decode(indices):\n",
    "    return ''.join([i2ch.get(idx, '') for idx in indices if idx != 0])\n",
    "\n",
    "for sent in translations.cpu().numpy():\n",
    "    print(decode(sent))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f931e5e",
   "metadata": {},
   "source": [
    "# Evaluate Transformer BLEU\n",
    "This notebook loads the saved vocab and model, runs generation on a subset of the dataset, and computes corpus BLEU using utils.bleu_score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60675340",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from utils import pickle as load_pickle, bleu_score\n",
    "from transformer import TransformerWithPhrase, TransformerConfig\n",
    "from preprocessing import preprocess_with_phrases, extract_7_phrases\n",
    "\n",
    "# Settings\n",
    "sequence_len = 128\n",
    "min_len = 5\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de37694f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded checkpoint: model.pth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TransformerWithPhrase(\n",
       "  (token_embedding): Embedding(790, 240)\n",
       "  (phrase_embedding): Embedding(8, 16)\n",
       "  (pos_embedding): Embedding(128, 256)\n",
       "  (encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-3): 4 x TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): TransformerDecoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-3): 4 x TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (fc_out): Linear(in_features=256, out_features=790, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load vocab pickles (must match the model used during training)\n",
    "assert os.path.exists('ch2i.pkl'), \"model/ch2i.pkl not found\"\n",
    "assert os.path.exists('phrase2idx.pkl'), \"model/phrase2idx.pkl not found\"\n",
    "ch2i = load_pickle('ch2i.pkl')\n",
    "phrase2idx = load_pickle('phrase2idx.pkl')\n",
    "i2ch = {i: c for c, i in ch2i.items()}\n",
    "\n",
    "# Instantiate model config and model\n",
    "mconfig = TransformerConfig(\n",
    "    vocab_size=len(ch2i),\n",
    "    sequence_len=sequence_len,\n",
    "    nblock=4,\n",
    "    nhead=8,\n",
    "    embed_dim=256,\n",
    "    phrase_emb_dim=16,\n",
    ")\n",
    "model = TransformerWithPhrase(mconfig, phrase_vocab_size=len(phrase2idx))\n",
    "\n",
    "# Try loading checkpoint if available (optional names tried)\n",
    "ckpt_paths = ['model.pth', 'model_checkpoint.pth', 'model/transformer.pth']\n",
    "for p in ckpt_paths:\n",
    "    if os.path.exists(p):\n",
    "        state = torch.load(p, map_location=device)\n",
    "        # handle state dict saved directly or under 'model' key\n",
    "        if isinstance(state, dict) and 'model_state_dict' in state:\n",
    "            model.load_state_dict(state['model_state_dict'])\n",
    "        elif isinstance(state, dict) and 'state_dict' in state:\n",
    "            model.load_state_dict(state['state_dict'])\n",
    "        else:\n",
    "            try:\n",
    "                model.load_state_dict(state)\n",
    "            except Exception:\n",
    "                # best-effort: skip if incompatible\n",
    "                print(f'Could not load checkpoint {p} into model; skipping.')\n",
    "        print('Loaded checkpoint:', p)\n",
    "        break\n",
    "\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e918618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset and preprocess (use same preprocessing as training)\n",
    "df = pd.read_csv('hindi_english_parallel.csv')\n",
    "en_texts = df['english'].astype(str).tolist()\n",
    "hi_texts = df['hindi'].astype(str).tolist()\n",
    "\n",
    "# Optionally limit number of evaluation samples to speed up evaluation\n",
    "max_eval = 200\n",
    "en_texts = en_texts[:max_eval]\n",
    "hi_texts = hi_texts[:max_eval]\n",
    "\n",
    "en_proc, hi_proc, phrase_tags = preprocess_with_phrases(en_texts, hi_texts, min_len, sequence_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00cbf392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generation + BLEU collection\n",
    "def encode_source(s, ch2i, seq_len):\n",
    "    ids = [ch2i.get(c, 0) for c in s]\n",
    "    ids = ids[:seq_len] + [0] * (seq_len - len(ids))\n",
    "    return ids\n",
    "\n",
    "def encode_phrases(tags, phrase2idx, seq_len):\n",
    "    ids = [phrase2idx.get(t, 0) for t in tags]\n",
    "    ids = ids[:seq_len] + [0] * (seq_len - len(ids))\n",
    "    return ids\n",
    "\n",
    "def decode_preds(pred_indices, i2ch):\n",
    "    # pred_indices: list or 1D numpy array of ints\n",
    "    return ''.join([i2ch.get(int(i), '') for i in pred_indices if int(i) != 0])\n",
    "\n",
    "references = []\n",
    "candidates = []\n",
    "\n",
    "for src_proc, tgt_ref, tags in zip(en_proc, hi_texts, phrase_tags):\n",
    "    src_ids = encode_source(src_proc, ch2i, sequence_len)\n",
    "    p_ids = encode_phrases(tags, phrase2idx, sequence_len)\n",
    "    src_tensor = torch.tensor([src_ids], dtype=torch.long, device=device)\n",
    "    p_tensor = torch.tensor([p_ids], dtype=torch.long, device=device)\n",
    "    with torch.no_grad():\n",
    "        pred = model.generate(src_tensor, p_tensor, max_len=sequence_len, start_token=1)  # shape (1, L)\n",
    "    pred_np = pred[0].cpu().numpy()\n",
    "    cand = decode_preds(pred_np, i2ch)\n",
    "    candidates.append(cand)\n",
    "    # utils.bleu_score expects references as list-of-lists of reference sentences\n",
    "    references.append([tgt_ref])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45a62a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1: 0.00, BLEU-2: 0.00, BLEU-3: 0.00, BLEU-4: 0.00\n",
      "SRC: Give your application an accessibility workout\n",
      "REF: अपने अनुप्रयोग को पहुंचनीयता व्यायाम का लाभ दें\n",
      "PRED: --------------------------------------------------------------------------------------------------------------------------------\n",
      "---\n",
      "SRC: Accerciser Accessibility Explorer\n",
      "REF: एक्सेर्साइसर पहुंचनीयता अन्वेषक\n",
      "PRED: --------------------------------------------------------------------------------------------------------------------------------\n",
      "---\n",
      "SRC: The default plugin layout for the bottom panel\n",
      "REF: निचले पटल के लिए डिफोल्ट प्लग-इन खाका\n",
      "PRED: --------------------------------------------------------------------------------------------------------------------------------\n",
      "---\n",
      "SRC: The default plugin layout for the top panel\n",
      "REF: ऊपरी पटल के लिए डिफोल्ट प्लग-इन खाका\n",
      "PRED: --------------------------------------------------------------------------------------------------------------------------------\n",
      "---\n",
      "SRC: A list of plugins that are disabled by default\n",
      "REF: उन प्लग-इनों की सूची जिन्हें डिफोल्ट रूप से निष्क्रिय किया गया है\n",
      "PRED: --------------------------------------------------------------------------------------------------------------------------------\n",
      "---\n",
      "SRC: Highlight duration\n",
      "REF: अवधि को हाइलाइट रकें\n",
      "PRED: --------------------------------------------------------------------------------------------------------------------------------\n",
      "---\n",
      "SRC: The duration of the highlight box when selecting accessible nodes\n",
      "REF: पहुंचनीय आसंधि (नोड) को चुनते समय हाइलाइट बक्से की अवधि\n",
      "PRED: --------------------------------------------------------------------------------------------------------------------------------\n",
      "---\n",
      "SRC: Highlight border color\n",
      "REF: सीमांत (बोर्डर) के रंग को हाइलाइट करें\n",
      "PRED: --------------------------------------------------------------------------------------------------------------------------------\n",
      "---\n",
      "SRC: The color and opacity of the highlight border.\n",
      "REF: हाइलाइट किए गए सीमांत का रंग और अपारदर्शिता। \n",
      "PRED: --------------------------------------------------------------------------------------------------------------------------------\n",
      "---\n",
      "SRC: Highlight fill color\n",
      "REF: भराई के रंग को हाइलाइट करें\n",
      "PRED: --------------------------------------------------------------------------------------------------------------------------------\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# Compute BLEU using utils.bleu_score\n",
    "bleu1, bleu2, bleu3, bleu4 = bleu_score(references, candidates)\n",
    "print(f'BLEU-1: {bleu1:.2f}, BLEU-2: {bleu2:.2f}, BLEU-3: {bleu3:.2f}, BLEU-4: {bleu4:.2f}')\n",
    "\n",
    "# Optionally print a few examples\n",
    "for i in range(min(10, len(candidates))):\n",
    "    print('SRC:', en_texts[i])\n",
    "    print('REF:', hi_texts[i])\n",
    "    print('PRED:', candidates[i])\n",
    "    print('---')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
